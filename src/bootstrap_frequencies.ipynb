{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20fec34a-044d-482f-938c-0596078bd494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc25fcd-f6af-4dc7-b163-d46c7b188643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_95CI(signal, alpha=5.0):\n",
    "    \"\"\"Computes the (default to 95%) confidence intervals of a sequential signal.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : {array-like} of shape (n_samples, n_timesteps).\n",
    "    The matrix of samples. Each row represents a sample, while each column is associated to a timestep.\n",
    "\n",
    "    alpha : float.\n",
    "    1 - CI_range, where CI_range represents the range of the confidence interval.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    CI95_lower : {array} of shape (n_timesteps, ).\n",
    "    The lower bound of the (1 - alpha) confidence interval.\n",
    "\n",
    "    CI95_upper : {array} of shape (n_timesteps, ).\n",
    "    The upper bound of the (1 - alpha) confidence interval.\n",
    "    \"\"\"\n",
    "    CI95_lower = []\n",
    "    CI95_upper = []\n",
    "\n",
    "    \n",
    "        \n",
    "    drawn_at_time_t = signal.copy() # Gather the samples at time t\n",
    "    lower_p = alpha / 2.0 # Computes the lower bound\n",
    "    lower = np.percentile(drawn_at_time_t, lower_p) # Retrieves the observation at the lower percentile index\n",
    "    upper_p = (100 - alpha) + (alpha / 2.0) # Computes the upper bound\n",
    "    upper = np.percentile(drawn_at_time_t, upper_p) # Retrieves the observation at the upper percentile index\n",
    "\n",
    "    CI95_lower.append(lower)\n",
    "    CI95_upper.append(upper)\n",
    "        \n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46741001-f0e8-47fe-90c9-8a38676c904d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_HPV</th>\n",
       "      <th>obs_crAssphages</th>\n",
       "      <th>inhibition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dateStart</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-24</th>\n",
       "      <td>18613.855375</td>\n",
       "      <td>2.663931e+07</td>\n",
       "      <td>0.778384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-28</th>\n",
       "      <td>32242.166419</td>\n",
       "      <td>5.253436e+07</td>\n",
       "      <td>0.515037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-31</th>\n",
       "      <td>33190.381878</td>\n",
       "      <td>3.806105e+07</td>\n",
       "      <td>0.479286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-04</th>\n",
       "      <td>64956.400453</td>\n",
       "      <td>2.717509e+07</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-07</th>\n",
       "      <td>51089.113535</td>\n",
       "      <td>2.478178e+07</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 obs_HPV  obs_crAssphages  inhibition\n",
       "dateStart                                            \n",
       "2024-01-24  18613.855375     2.663931e+07    0.778384\n",
       "2024-01-28  32242.166419     5.253436e+07    0.515037\n",
       "2024-01-31  33190.381878     3.806105e+07    0.479286\n",
       "2024-02-04  64956.400453     2.717509e+07    0.000000\n",
       "2024-02-07  51089.113535     2.478178e+07    0.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '../data/Données HPV V2.xlsx'\n",
    "\n",
    "data_HPV_HF = pd.read_excel(filepath, sheet_name='Hautes fréquences')\n",
    "data_HPV_HF = data_HPV_HF.iloc[:, [1, -3, -8, 5]]\n",
    "data_HPV_HF = data_HPV_HF.loc[1:]\n",
    "data_HPV_HF.columns = ['dateStart', 'obs_HPV', 'obs_crAssphages', 'inhibition']\n",
    "\n",
    "# Manual inputs for dateStart\n",
    "data_HPV_HF.dateStart = data_HPV_HF.dateStart.replace('03/07/2024', '2024-07-03')\n",
    "data_HPV_HF.dateStart = data_HPV_HF.dateStart.replace('01/09/2024', '2024-09-01')\n",
    "data_HPV_HF.dateStart = data_HPV_HF.dateStart.replace('04/09/2024', '2024-09-04')\n",
    "data_HPV_HF.dateStart = data_HPV_HF.dateStart.replace('10/08/2024', '2024-08-10')\n",
    "data_HPV_HF.dateStart = data_HPV_HF.dateStart.replace('14/08/2024', '2024-08-14')\n",
    "data_HPV_HF.dateStart = data_HPV_HF.dateStart.replace('25/08/2024', '2024-08-25')\n",
    "data_HPV_HF.dateStart = data_HPV_HF.dateStart.replace('03/11/2024', '2024-11-03')\n",
    "data_HPV_HF.dateStart = data_HPV_HF.dateStart.replace('06/11/2024', '2024-11-06')\n",
    "data_HPV_HF.dateStart = data_HPV_HF.dateStart.replace('10/11/2024', '2024-11-10')\n",
    "data_HPV_HF.dateStart = data_HPV_HF.dateStart.replace('01/12/2024', '2024-12-01')\n",
    "data_HPV_HF.dateStart = data_HPV_HF.dateStart.replace('04/12/2024', '2024-12-04')\n",
    "data_HPV_HF.dateStart = data_HPV_HF.dateStart.replace('08/12/2024', '2024-12-08')\n",
    "data_HPV_HF.dateStart = data_HPV_HF.dateStart.replace('05/01/2025', '2025-01-05')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_HPV_HF.dateStart = pd.to_datetime(data_HPV_HF.dateStart)#, format='DD/MM/YYYY')\n",
    "data_HPV_HF.obs_HPV = pd.to_numeric(data_HPV_HF.obs_HPV)\n",
    "data_HPV_HF.obs_crAssphages = pd.to_numeric(data_HPV_HF.obs_crAssphages)\n",
    "data_HPV_HF.inhibition = pd.to_numeric(data_HPV_HF.inhibition)\n",
    "data_HPV_HF.sort_values(by='dateStart', inplace=True)\n",
    "data_HPV_HF.dateStart.value_counts().head()\n",
    "data_HPV_HF.drop_duplicates(subset='dateStart', inplace=True)\n",
    "data_HPV_HF.set_index('dateStart', inplace=True)\n",
    "data_HPV_HF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "613bcd46-68c6-483b-acf6-31bd4232dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('../data/bootstrap.xlsx', sheet_name='Feuil1')\n",
    "data.drop('Date', axis=1, inplace=True)\n",
    "data['dateStart'] = data_HPV_HF.index.tolist()\n",
    "HPV_types = data.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbf318ea-a3df-4345-94f3-f4f3830a9d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_dict = {}\n",
    "for this_type in HPV_types:\n",
    "    frequency_dict[this_type] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b577dd26-5184-4636-bd02-c2ebe083bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_frequency_dict = {}\n",
    "for this_type in HPV_types:\n",
    "    mean_frequency_dict[this_type] = data[this_type].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1972bb3-fa95-46e2-8c2f-68ec81e8ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_iters = 1000\n",
    "complete_indexes = data.index.tolist()\n",
    "RANDOM_SEED = 48 # for reproducibility\n",
    "\n",
    "for j in range(bootstrap_iters):\n",
    "    np.random.seed(RANDOM_SEED+j)\n",
    "    sub_indexes = np.random.choice(complete_indexes, size=len(complete_indexes), replace=True)\n",
    "\n",
    "    for this_type in list(frequency_dict.keys()):\n",
    "        these_values = data.loc[sub_indexes, this_type].values\n",
    "        this_freq = np.sum(these_values)\n",
    "        frequency_dict[this_type].append(this_freq)\n",
    "\n",
    "for this_type in list(frequency_dict.keys()):\n",
    "    frequency_dict[this_type] = np.array(frequency_dict[this_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27e5b46a-9332-4dd2-89d2-88244dc44801",
   "metadata": {},
   "outputs": [],
   "source": [
    "CILs, CIUs = [], []\n",
    "for this_type in list(mean_frequency_dict.keys()):\n",
    "    CIL, CIU = get_95CI(frequency_dict[this_type])\n",
    "    CILs.append(CIL)\n",
    "    CIUs.append(CIU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8d61429-bf72-4c70-8f45-6ab1de16e1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesis = pd.DataFrame()\n",
    "synthesis['HPV_type'] = list(mean_frequency_dict.keys())\n",
    "synthesis['mean_frequency'] = list(mean_frequency_dict.values())\n",
    "synthesis['frequency_CIL'] = CILs\n",
    "synthesis['frequency_CIU'] = CIUs\n",
    "synthesis.head()\n",
    "\n",
    "synthesis.to_csv('../outputs/files/bootstrap_frequencies.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89914860-b3e9-40ab-bdc0-c218f403f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Weekly sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18d9386b-da13-480f-90e4-84fcd5b3f4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extending the previous test to all different subtypes:\n",
    "\n",
    "input_replicate_1 = pd.read_excel(\"../data/pvalue-HPV.xlsx\", sheet_name='Essai 1')\n",
    "input_replicate_2 = pd.read_excel(\"../data/pvalue-HPV.xlsx\", sheet_name='Essai 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ea05d41-d899-4367-9164-cd6d43bb4f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_replicate(input_replicate, this_type):\n",
    "\n",
    "    subcols = ['Date', this_type]\n",
    "    sub_replicate = input_replicate.loc[::, subcols]\n",
    "    sub_replicate = sub_replicate.loc[~sub_replicate.Date.isna()]\n",
    "    \n",
    "    original_date = ['03/07/2024', '10/08/2024', '14/08/2024',\n",
    "                    '03/11/2024', '06/11/2024', '10/11/2024',\n",
    "                    '25/08/2024', '01/09/2024', '04/09/2024',\n",
    "                    '18/09/2024', '16/10/2024', '01/12/2024',\n",
    "                    '04/12/2024', '08/12/2024', '01/01/2025',\n",
    "                    '05/01/2025'\n",
    "                     ]\n",
    "    \n",
    "    modified_date = ['2024-07-03 00:00:00', '2024-08-10 00:00:00', '2024-08-14 00:00:00',\n",
    "                     '2024-11-03 00:00:00', '2024-11-06 00:00:00', '2024-11-10 00:00:00',\n",
    "                     '2024-08-25 00:00:00', '2024-09-01 00:00:00', '2024-09-04 00:00:00',\n",
    "                     '2024-09-18 00:00:00', '2024-10-16 00:00:00', '2024-12-01 00:00:00',\n",
    "                     '2024-12-04 00:00:00', '2024-12-08 00:00:00', '2025-01-01 00:00:00',\n",
    "                     '2025-01-05 00:00:00']\n",
    "    \n",
    "    for date_index, date in enumerate(original_date):\n",
    "        sub_replicate.Date = sub_replicate.Date.replace(date, modified_date[date_index])\n",
    "    \n",
    "    sub_replicate.Date = pd.to_datetime(sub_replicate.Date)\n",
    "\n",
    "    # dealing with 2024-08-21 duplicates\n",
    "    duplicate_indexes = sub_replicate.loc[sub_replicate.Date=='2024-08-21'].index.values\n",
    "    \n",
    "    if sub_replicate.loc[(sub_replicate.Date=='2024-08-21')&(~sub_replicate[this_type].isna())].shape[0]==2:\n",
    "        sub_replicate.drop(duplicate_indexes[-1], axis=0, inplace=True)\n",
    "\n",
    "    elif sub_replicate.loc[(sub_replicate.Date=='2024-08-21')&(~sub_replicate[this_type].isna())].shape[0]==0:\n",
    "        sub_replicate.drop(duplicate_indexes[-1], axis=0, inplace=True)\n",
    "\n",
    "    elif sub_replicate.loc[(sub_replicate.Date=='2024-08-21')&(~sub_replicate[this_type].isna())].shape[0]==1:\n",
    "        this_index = sub_replicate.loc[(sub_replicate.Date=='2024-08-21')&(~sub_replicate[this_type].isna())].index.tolist()[0]\n",
    "        dropme = duplicate_indexes[np.where(duplicate_indexes!=this_index)[0][0]]\n",
    "        sub_replicate.drop(dropme, axis=0, inplace=True)\n",
    "\n",
    "    sub_replicate = sub_replicate.rename(columns={'Date':'dateStart'})\n",
    "    sub_replicate.set_index('dateStart', inplace=True)\n",
    "    \n",
    "    return sub_replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a5fca88-d59a-445a-8d92-cd3dbd6f386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_and_get_samples(this_type):\n",
    "    \n",
    "    sr1_6 = process_replicate(input_replicate_1, this_type)\n",
    "    sr2_6 = process_replicate(input_replicate_2, this_type)\n",
    "\n",
    "    sr_6 = sr1_6.join(sr2_6, lsuffix='_1', rsuffix='_2')\n",
    "\n",
    "    sr_6.reset_index(inplace=True)\n",
    "    sr_6['year'] = sr_6.dateStart.dt.year\n",
    "    sr_6['month'] = sr_6.dateStart.dt.month\n",
    "    sr_6['week'] = sr_6.dateStart.dt.isocalendar().week\n",
    "\n",
    "    sr_6['year_week'] = sr_6['year'].astype(str) + '-' + sr_6['week'].astype(str)\n",
    "    sr_6['year_month'] = sr_6['year'].astype(str) + '-' + sr_6['month'].astype(str)\n",
    "\n",
    "    for column in [this_type + '_1', this_type + '_2']:\n",
    "        sr_6[column].replace(' NA', np.nan, inplace=True)\n",
    "        sr_6[column].replace('NA ', np.nan, inplace=True)\n",
    "        sr_6[column] = pd.to_numeric(sr_6[column])\n",
    "    \n",
    "    return sr_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07e803f3-77c4-404e-8ec5-dd401e7ac67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### To account for the resdiual bias (some weeks have 1 sample, one have 3 samples, the rest have 2 samples)\n",
    "### we gonna take a cut with a sliding window\n",
    "### say we start with 100 samples\n",
    "### the biweekly model is gonna cut the 100 samples into 50 pairs\n",
    "### we then gonna take one index among each pair\n",
    "### the bimonthly model is gonna cut the 100 samples into 25 set of 4\n",
    "### we gonna take one among 4\n",
    "### and finally the monthly model is gonna cut the 100 samples into 12 sets of 8 \n",
    "### lets do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c3a72d4-af86-4749-8499-b5e263d7c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detection_distribution_weekly(df_replicates):\n",
    "    bootstrap_iters = 1000\n",
    "    RANDOM_SEED = 48 # for reproducibility\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "\n",
    "    set_of_indexes = df_replicates.index.values.reshape(-1, 2)\n",
    "    detection_distribution = []\n",
    "    for this_bootstrap_iter in range(bootstrap_iters):\n",
    "        detected = 0\n",
    "        considered = 0\n",
    "        for k in range(set_of_indexes.shape[0]):\n",
    "            considered+=1\n",
    "            \n",
    "            eligible_indexes = set_of_indexes[k]\n",
    "            this_drawn_index = np.random.choice(eligible_indexes, size=1, replace=True)[0]\n",
    "            these_drawn_values = df_replicates.iloc[this_drawn_index, [1, 2]].values.astype(float)\n",
    "            \n",
    "            if ~np.isnan(these_drawn_values).all():\n",
    "                detected+=1\n",
    "                \n",
    "        detection_distribution.append(100 * detected / considered)\n",
    "    \n",
    "    detection_distribution = np.array(detection_distribution)\n",
    "\n",
    "    return detection_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "596cacfe-6237-4d11-a7ae-92803abccf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "types_list = input_replicate_1.columns[3:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36eaa0cf-e6cf-479d-b165-5d63ab86cf13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distribution_type_dict = {}\n",
    "\n",
    "for this_type in types_list:    \n",
    "    df_replicates = join_and_get_samples(this_type)\n",
    "    this_detection_distribution = get_detection_distribution_weekly(df_replicates)\n",
    "    distribution_type_dict[this_type] = this_detection_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "198b2f9b-a3a8-46d3-b458-363ebde373ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_distributions = []\n",
    "CIL_distributions = []\n",
    "CIU_distributions = []\n",
    "\n",
    "for this_type in list(distribution_type_dict.keys()):\n",
    "\n",
    "    mean_distribution = distribution_type_dict[this_type].mean()\n",
    "    CIL, CIU = get_95CI(distribution_type_dict[this_type])\n",
    "\n",
    "    mean_distributions.append(mean_distribution)\n",
    "    CIL_distributions.append(CIL)\n",
    "    CIU_distributions.append(CIU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0ae4d0e-bff5-41fa-b613-b238a522d922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  HPV_type  mean_frequency  frequency_CIL  frequency_CIU\n",
      "0    HPV 6          93.090          88.00           98.0\n",
      "1   HPV 11          21.028          14.00           28.0\n",
      "2   HPV 16          20.816          14.00           28.0\n",
      "3   HPV 18           4.944           1.95           10.0\n",
      "4   HPV 26           4.954           1.95           10.0\n"
     ]
    }
   ],
   "source": [
    "synthesis = pd.DataFrame()\n",
    "synthesis['HPV_type'] = list(distribution_type_dict.keys())\n",
    "synthesis['mean_frequency'] = mean_distributions\n",
    "synthesis['frequency_CIL'] = CIL_distributions\n",
    "synthesis['frequency_CIU'] = CIU_distributions\n",
    "print(synthesis.head())\n",
    "synthesis.to_csv('../outputs/files/bootstrap_frequencies_weekly_2.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d78cd6ea-2f1a-4ea1-91aa-5df865af297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detection_distribution_bimonthly(df_replicates):\n",
    "    bootstrap_iters = 1000\n",
    "    RANDOM_SEED = 48 # for reproducibility\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "\n",
    "    set_of_indexes = df_replicates.index.values.reshape(-1, 4)\n",
    "    detection_distribution = []\n",
    "    for this_bootstrap_iter in range(bootstrap_iters):\n",
    "        detected = 0\n",
    "        considered = 0\n",
    "        for k in range(set_of_indexes.shape[0]):\n",
    "            considered+=1\n",
    "            \n",
    "            eligible_indexes = set_of_indexes[k]\n",
    "            this_drawn_index = np.random.choice(eligible_indexes, size=1, replace=True)[0]\n",
    "            these_drawn_values = df_replicates.iloc[this_drawn_index, [1, 2]].values.astype(float)\n",
    "            \n",
    "            if ~np.isnan(these_drawn_values).all():\n",
    "                detected+=1\n",
    "                \n",
    "        detection_distribution.append(100 * detected / considered)\n",
    "    \n",
    "    detection_distribution = np.array(detection_distribution)\n",
    "\n",
    "    return detection_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d49b2c0-79e2-4d66-82b7-8eaf4cbe7894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distribution_type_dict = {}\n",
    "\n",
    "for this_type in types_list:\n",
    "    df_replicates = join_and_get_samples(this_type)\n",
    "    this_detection_distribution = get_detection_distribution_bimonthly(df_replicates)\n",
    "    distribution_type_dict[this_type] = this_detection_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f9e7495-2137-4deb-b2ea-1a92b2a008a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_distributions = []\n",
    "CIL_distributions = []\n",
    "CIU_distributions = []\n",
    "\n",
    "for this_type in list(distribution_type_dict.keys()):\n",
    "\n",
    "    mean_distribution = distribution_type_dict[this_type].mean()\n",
    "    CIL, CIU = get_95CI(distribution_type_dict[this_type])\n",
    "\n",
    "    mean_distributions.append(mean_distribution)\n",
    "    CIL_distributions.append(CIL)\n",
    "    CIU_distributions.append(CIU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b41f85e7-686b-454a-a1a8-0cf413999866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  HPV_type  mean_frequency  frequency_CIL  frequency_CIU\n",
      "0    HPV 6          92.996           84.0          100.0\n",
      "1   HPV 11          20.660            8.0           36.0\n",
      "2   HPV 16          20.740            8.0           32.1\n",
      "3   HPV 18           4.956            0.0           12.0\n",
      "4   HPV 26           5.236            0.0           12.0\n"
     ]
    }
   ],
   "source": [
    "synthesis = pd.DataFrame()\n",
    "synthesis['HPV_type'] = list(distribution_type_dict.keys())\n",
    "synthesis['mean_frequency'] = mean_distributions\n",
    "synthesis['frequency_CIL'] = CIL_distributions\n",
    "synthesis['frequency_CIU'] = CIU_distributions\n",
    "print(synthesis.head())\n",
    "synthesis.to_csv('../outputs/files/bootstrap_frequencies_bimonthly_2.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d45fd682-b8ce-42e4-ba1f-90055b9d3b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detection_distribution_monthly(df_replicates):\n",
    "    bootstrap_iters = 1000\n",
    "    RANDOM_SEED = 48 # for reproducibility\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "\n",
    "    indexes = df_replicates.index.values\n",
    "    set_of_indexes = indexes[:len(indexes)//8 * 8].reshape(-1, 8).tolist()\n",
    "    if len(indexes) % 8:\n",
    "        set_of_indexes[-1].append(indexes[-1])\n",
    "    set_of_indexes = np.array(set_of_indexes, dtype=object)\n",
    "\n",
    "    detection_distribution = []\n",
    "    for this_bootstrap_iter in range(bootstrap_iters):\n",
    "        detected = 0\n",
    "        considered = 0\n",
    "        for k in range(set_of_indexes.shape[0]):\n",
    "            considered+=1\n",
    "            \n",
    "            eligible_indexes = set_of_indexes[k]\n",
    "            this_drawn_index = np.random.choice(eligible_indexes, size=1, replace=True)[0]\n",
    "            these_drawn_values = df_replicates.iloc[this_drawn_index, [1, 2]].values.astype(float)\n",
    "            \n",
    "            if ~np.isnan(these_drawn_values).all():\n",
    "                detected+=1\n",
    "                \n",
    "        detection_distribution.append(100 * detected / considered)\n",
    "    \n",
    "    detection_distribution = np.array(detection_distribution)\n",
    "\n",
    "    return detection_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "322158e3-6d8d-437d-b69a-5046bbb2b99f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distribution_type_dict = {}\n",
    "\n",
    "for this_type in types_list:    \n",
    "    df_replicates = join_and_get_samples(this_type)\n",
    "    this_detection_distribution = get_detection_distribution_monthly(df_replicates)\n",
    "    distribution_type_dict[this_type] = this_detection_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a508e37-24f0-49de-a629-24f6d81a059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_distributions = []\n",
    "CIL_distributions = []\n",
    "CIU_distributions = []\n",
    "\n",
    "for this_type in list(distribution_type_dict.keys()):\n",
    "\n",
    "    mean_distribution = distribution_type_dict[this_type].mean()\n",
    "    CIL, CIU = get_95CI(distribution_type_dict[this_type])\n",
    "\n",
    "    mean_distributions.append(mean_distribution)\n",
    "    CIL_distributions.append(CIL)\n",
    "    CIU_distributions.append(CIU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "905675c6-7439-4d86-8273-ee19f32bae03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  HPV_type  mean_frequency  frequency_CIL  frequency_CIU\n",
      "0    HPV 6       92.558333           75.0     100.000000\n",
      "1   HPV 11       21.125000            0.0      41.666667\n",
      "2   HPV 16       18.383333            0.0      41.666667\n",
      "3   HPV 18        4.475000            0.0      16.666667\n",
      "4   HPV 26        5.425000            0.0      16.666667\n"
     ]
    }
   ],
   "source": [
    "synthesis = pd.DataFrame()\n",
    "synthesis['HPV_type'] = list(distribution_type_dict.keys())\n",
    "synthesis['mean_frequency'] = mean_distributions\n",
    "synthesis['frequency_CIL'] = CIL_distributions\n",
    "synthesis['frequency_CIU'] = CIU_distributions\n",
    "print(synthesis.head())\n",
    "synthesis.to_csv('../outputs/files/bootstrap_frequencies_monthly_2.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3877132-b773-46af-a401-1cf7a4153040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
